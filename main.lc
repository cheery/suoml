import grammar

language = grammar.read_file("suoml.grammar")

main = ():
    parse = language.read_file("sample.fml")
    decls = parse.traverse((rule, args, loc):
        return getattr(actions, rule)(args...))

    type_env = {}
    populate_type_env(type_env)

    # Assuming that the subtyping algorithm is going to require a similar
    # treatment as the Algorithm W in order to handle recursive clauses
    # correctly. Therefore this builds the dependency graph so that the
    # SCC algorithm then sort the expressions out.
    decl_by_name = {}
    for decl in decls
        decl_by_name[decl.name] = decl
    for decl in decls
        for name in decl.free_vars
            if name in decl_by_name
                decl.depends.add(decl_by_name[name])
            elif name not in type_env
                assert false, ["not present", name]

    out = tarjan_find_scc(decls)

    visited = set()

    for name in type_env
        print(name, "::", to_raw_type(type_env[name]))

    for group in out
        if group.length != 1
            print("Error: not ready for recursive definitions yet")
            print("SCC detected:")
            for decl in group
                print(" ", decl)
            exit(1)

        decl = group.pop()
        scheme = inference(Abs(decl.args, decl.body), type_env, visited)
        type_env[decl.name] = generalize(scheme)

        scheme_r = reduce(scheme)
        print(decl.name, "::", to_raw_type(scheme_r))

populate_type_env = (type_env):
    print_t = Node(+1)
    arg_t = Node(-1)
    arg_t.heads.add("string")
    print_t.add_transition(["dom", 0], arg_t)
    result_t = Node(+1)
    result_t.heads.add("unit")
    print_t.add_transition(["cod"], result_t)
    print_t.heads.add("->")
    type_env['print'] = object({
        graph = set([print_t, arg_t, result_t])
        root = print_t
    })

    add_t = Node(+1)
    arg_0 = Node(-1)
    arg_1 = Node(-1)
    res_t = Node(+1)
    add_t.add_transition(["dom", 0], arg_0)
    add_t.add_transition(["dom", 1], arg_1)
    add_t.add_transition(["cod"], res_t)
    add_t.heads.add("->")
    arg_0.add_flow(res_t)
    arg_1.add_flow(res_t)
    type_env['add'] = object({
        graph = set([add_t, arg_0, arg_1, res_t])
        root = add_t
    })
    arg_0.heads.add("(add)")
    arg_1.heads.add("(add)")

    gt_t = Node(+1)
    arg_0 = Node(-1)
    arg_1 = Node(-1)
    comb_t = Node(+1)
    res_t = Node(+1)
    res_t.heads.add("bool")
    gt_t.add_transition(["dom", 0], arg_0)
    gt_t.add_transition(["dom", 1], arg_1)
    gt_t.add_transition(["cod"], res_t)
    gt_t.heads.add("->")
    arg_0.heads.add("(ord)")
    arg_1.heads.add("(ord)")
    # TODO: There won't happen additional checks when we add this
    #       in. Therefore this is 'redundant' information except
    #       for the user, and for the subsequent compiler step
    #       that has to select an implementation for the function.
    comb_t.add_flow(arg_0)
    comb_t.add_flow(arg_1)
    type_env['gt'] = object({
        graph = set([gt_t, arg_0, arg_1, res_t, comb_t])
        root = gt_t
    })

    vec3_t = Node(+1)
    arg_0 = Node(-1)
    arg_1 = Node(-1)
    arg_2 = Node(-1)
    res_t = Node(+1)
    res_t.heads.add("vec")
    vec3_t.add_transition(["dom", 0], arg_0)
    vec3_t.add_transition(["dom", 1], arg_1)
    vec3_t.add_transition(["dom", 2], arg_2)
    vec3_t.add_transition(["cod"], res_t)
    vec3_t.heads.add("->")
    arg_0.heads.add("(vec)")
    arg_1.heads.add("(vec)")
    arg_2.heads.add("(vec)")
    res_t.add_flow(arg_0)
    res_t.add_flow(arg_1)
    res_t.add_flow(arg_2)
    type_env['vec3'] = object({
        graph = set([vec3_t, arg_0, arg_1, arg_2, res_t])
        root = vec3_t
    })


# TODO: This may be doing really silly things by
#       generalizing every use of a variable.
inference = (a, type_env, visited):
    if isinstance(a, Abs)
        graph = set()
        type_env = dict(type_env)
        ports = []
        for arg in a.args
            port = new_port(graph)
            ports.append(port)
            type_env[arg] = object({
                graph = set()
                root = port.output
            })
        result = inference(a.body, type_env, visited)
        graph.update(result.graph)
        functype = Node(+1)
        for i in range(ports.length)
            functype.add_transition(
                ["dom", i], ports[i].input)
        functype.add_transition(["cod"], result.root)
        functype.heads.add("->")
        return object({
            graph = graph
            root = functype
        })
    if isinstance(a, App)
        graph = set()

        lhs_scheme = inference(a.lhs, type_env, visited)
        graph.update(lhs_scheme.graph)
        calltype = Node(-1)
        calltype.heads.add("->")
        i = 0
        for arg in a.args
            arg_scheme = inference(arg, type_env, visited)
            calltype.add_transition(["dom", i], arg_scheme.root)
            graph.update(arg_scheme.graph)
            i += 1
        result = new_port(graph)
        calltype.add_transition(
            ["cod"], result.input)
        biunify([lhs_scheme.root, calltype], visited)
        return object({
            graph = graph
            root = result.output
        })
    if isinstance(a, IfThenElse)
        graph = set()
        cond = inference(a.cond, type_env, visited)
        boolean = Node(-1)
        boolean.heads.add("bool")
        graph.add(boolean)
        biunify([cond, boolean], visited)
        t = inference(a.t, type_env, visited)
        f = inference(a.f, type_env, visited)
        result = new_port(graph)
        biunify([t, result.input], visited)
        biunify([f, result.input], visited)
        return object({
            graph = graph | cond.graph | t.graph | f.graph
            root = result.output
        })
    if isinstance(a, Let)
        lhs_scheme = inference(a.lhs, type_env, visited)
        type_env = dict(type_env)
        type_env[a.name] = generalize(lhs_scheme)
        rhs_scheme = inference(a.rhs, type_env, visited)
        return object({
            graph = lhs_scheme.graph | rhs_scheme.graph
            root = rhs_scheme.root
        })
    if isinstance(a, Var)
        return replicate(type_env[a.name])
    if isinstance(a, Lit)
        result = Node(+1)
        result.heads.add(a.type)
        return object({
            graph = set([result])
            root = result
        })
    assert false, ["unable to inference", a]

# Reduce and generalize are similar, but each serve
# very different purpose which makes it reasonable to
# have them apart.
generalize = (scheme):
    subsets = {} 
    flow_sets = {}

    reduce_subset = (pol, subset):
        if subset in subsets
            return subsets[subset]
        subsets[subset] = s = Node(pol)
        for n in subset
            s.heads.update(n.heads)
            try
                flow_sets[n].add(s)
            except KeyError as _
                flow_sets[n] = [s]
            for label, ws in n.p_transitions.items()
                for w in ws
                    s.add_transition(label, w)
            for label, ws in n.n_transitions.items()
                for w in ws
                    s.add_transition(label, w)
            # TODO: Check whether this does what expected.
            # Retains flow edges into the objects that are not
            # in the graph.
            for w in n.flow
                if w not in scheme.graph
                    s.add_flow(w)

        p_transitions = {}
        for label, ws in s.p_transitions.items()
            extern = set()
            for w in ws
                if w not in scheme.graph
                    extern.add(w)
            ws.difference_update(extern)
            p_transitions[label] = set([reduce_subset(pol, ws)]) | extern
        s.p_transitions = p_transitions

        n_transitions = {}
        for label, ws in s.n_transitions.items()
            extern = set()
            for w in ws
                if w not in scheme.graph
                    extern.add(w)
            ws.difference_update(extern)
            n_transitions[label] = set([reduce_subset(-pol, ws)]) | extern
        s.n_transitions = n_transitions

        return s

    node = scheme.root
    root = reduce_subset(node.pol, set([node]))
    for node, ss in flow_sets.items()
        continue if node.pol > 0
        for w in node.flow
            qq = flow_sets.get(w, [])
            for s in ss
                for q in qq
                    s.add_flow(q)
    
    return object({
        graph = set(subsets.values())
        root = root
    })


reduce = (scheme):
    subsets = {} 
    flow_sets = {}

    reduce_subset = (pol, subset):
        if subset in subsets
            return subsets[subset]
        subsets[subset] = s = Node(pol)
        for n in subset
            s.heads.update(n.heads)
            try
                flow_sets[n].add(s)
            except KeyError as _
                flow_sets[n] = [s]
            for label, ws in n.p_transitions.items()
                for w in ws
                    s.add_transition(label, w)
            for label, ws in n.n_transitions.items()
                for w in ws
                    s.add_transition(label, w)

        p_transitions = {}
        for label, ws in s.p_transitions.items()
            p_transitions[label] = set([reduce_subset(pol, ws)])
        s.p_transitions = p_transitions

        n_transitions = {}
        for label, ws in s.n_transitions.items()
            n_transitions[label] = set([reduce_subset(-pol, ws)])
        s.n_transitions = n_transitions

        return s

    stubs = set()

    node = scheme.root
    root = reduce_subset(node.pol, set([node]))
    for node, ss in flow_sets.items()
        continue if node.pol > 0
        for w in node.flow
            qq = flow_sets.get(w)
            if not qq
                stubs.add(w)
            else
                for s in ss
                    for q in qq
                        s.add_flow(q)

    # The 'reduce' is called in order to print the type. The person
    # reading the type is interested also in how the types relate to
    # each other, in which case we want to know flow information that
    # would not be important for the type inference.
    extra_groups = set()
    for stub in stubs
        x = stub.flow.intersection(flow_sets.keys())
        continue if x.length < 2
        extra_groups.add([stub.pol, x])

    # The size of extras here could be further reduced by
    # being clever, but not certain whether extra cleverness here
    # will help. TODO: check it out in practice
    extras = set()
    for pol, x in extra_groups
        w = Node(pol)
        for n in x
            for q in flow_sets[n]
                w.add_flow(q)
        extras.add(w)

    return object({
        graph = set(subsets.values()) | extras
        root = root
    })

to_raw_type = (scheme):
    flow_variables = greedy_biclique_decomposition(scheme.graph)
    get_raw_type = (node):
        if node.pol > 0
            typedecl = ["+"]
        else
            typedecl = ["-"]
        for head in node.heads
            typedecl.append(head)
        for label, ws in node.p_transitions.items()
            assert ws.length == 1
                "to_raw_type() only works on reduced type forms"
            w = iter(ws).next()
            typedecl.append([label] ++ get_raw_type(w))
        for label, ws in node.n_transitions.items()
            assert ws.length == 1
                "to_raw_type() only works on reduced type forms"
            w = iter(ws).next()
            typedecl.append([label] ++ get_raw_type(w))
        for v in flow_variables[node]
            typedecl.append(":" ++ (v + 10).to_string(35))
        return typedecl
    return get_raw_type(scheme.root)

greedy_biclique_decomposition = (graph):
    flow_edges = {}
    flow_variables = {}

    for node in graph
        edges = set()
        for w in node.flow
            if w in graph
                edges.add(w)
        flow_edges[node] = edges
        flow_variables[node] = []

    var_id = 0
    best_score = 1
    while best_score > 0
        best_biclique = null
        best_score = 0
        for node in graph
            a = flow_edges[node]
            if a.length == 0 # No biclique here.
                continue
            it = iter(a)
            b = set(flow_edges[it.next()])
            for w in it
                b.intersection_update(flow_edges[w])
            score = a.length * b.length
            if best_score < score
                best_score = score
                best_biclique = [a,b]
        if best_biclique
            a,b = best_biclique
            for n in a
                flow_variables[n].append(var_id)
                flow_edges[n].difference_update(b)
            for n in b
                flow_variables[n].append(var_id)
                flow_edges[n].difference_update(a)
            var_id += 1
    return flow_variables

replicate = (scheme):
    mapping = {}
    copy_node = (n):
        return n if n not in scheme.graph
        try
            return mapping[n]
        except KeyError as _
            mapping[n] = m = Node(n.pol)
            m.heads.update(n.heads)
            for w in n.flow
                m.flow.add(copy_node(w))
            for label, ws in n.p_transitions.items()
                for w in ws
                    m.add_transition(label, copy_node(w))
            for label, ws in n.n_transitions.items()
                for w in ws
                    m.add_transition(label, copy_node(w))
            return m
    return object({
        graph = set(mapping.values())
        root = copy_node(scheme.root)
    })

new_port = (graph):
    input = Node(-1)
    output = Node(+1)
    input.add_flow(output)
    graph.add(input)
    graph.add(output)
    return (input=input, output=output)

class Node
    +init = (self, pol=+1):
        self.pol = pol
        self.heads = set()
        self.flow = set()
        self.p_transitions = {}
        self.n_transitions = {}

    add_flow = (self, other):
        assert self.pol != other.pol
        self.flow.add(other)
        other.flow.add(self)

    add_transition = (self, label, port):
        if port.pol == self.pol
            transitions = self.p_transitions
        else
            transitions = self.n_transitions
        try
            transitions[label].add(port)
        except KeyError as _
            transitions[label] = set([port])

merge = (dst, src):
    assert dst.pol == src.pol
    for head in src.heads
        dst.heads.add(head)
    for v in src.flow
        dst.add_flow(v)
    for label, vs in src.p_transitions.items()
        try
            dst.p_transitions[label].update(vs)
        except KeyError as _
            dst.p_transitions[label] = set(vs)
    for label, vs in src.n_transitions.items()
        try
            dst.n_transitions[label].update(vs)
        except KeyError as _
            dst.n_transitions[label] = set(vs)

biunify = (pair, visited):
    return if pair in visited
    visited.add(pair)
    p, q = pair
    assert p.pol > q.pol, "biunify must have form (+p, -q)"

    # Check that subtyping constraints hold
    for x in p.heads
        for y in q.heads
            assert is_subtype(x, y), ["type error", x, y]

    # Rewrites the graph, eliminating the constraint
    for s in q.flow
        merge(s, p)
    for s in p.flow
        merge(s, q)

    # Constraint decomposition
    for label, ss in p.p_transitions.items()
        uu = q.p_transitions.get(label, [])
        for s in ss
            for u in uu
                biunify([s,u], visited)
    for label, ss in p.n_transitions.items()
        uu = q.n_transitions.get(label, [])
        for u in uu
            for s in ss
                biunify([u,s], visited)

is_subtype = (x, y):
    if x == y
        return true
    if x == "int" and y in int_traits
        return true
    if x == "vec" and y in vec_traits
        return true
    return false

int_traits = set([
    "(ord)", "(add)", "(vec)"
])
vec_traits = set([
    "(add)"
])


# The SCC finding is likely necessary for handling recursion.
# For now we use it to detect recursion so it fails before causing issues.
# https://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm
# TODO: improve the comments to explain the algorithm.
tarjan_find_scc = (decls):
    index = 0
    s = []
    output = []

    strong_connect = (decl):
        # set depth index for v to the smallest unused index
        decl.index = index
        decl.lowlink = index
        index += 1
        s.append(decl)
        decl.on_stack = true

        # consider successors of v
        for w in decl.depends
            if w.index == null # successor not visited yet
                strong_connect(w)
                decl.lowlink = min(decl.lowlink, w.lowlink)
            elif w.on_stack
                # successor w is in stack S, in the current SCC
                # Note: The next line may look odd - but is correct.
                # It says w.index not w.lowlink; that is deliberate and from the original paper
                decl.lowlink = min(decl.lowlink, w.index)
            # if w is not on stack, then (v,w) is a cross-edge in the DFS and
            #    must be ignored.
        # If v is a root node, pop the stack and generate an SCC
        if decl.lowlink == decl.index
            scc = set()
            w = null
            while w != decl
                w = s.pop()
                w.on_stack = false
                scc.add(w)
            output.append(scc)

    for decl in decls
        if decl.index == null
            strong_connect(decl)
    return output

class Def
    +init = (self, name, args, body):
        self.name = name
        self.args = args
        self.body = body
        self.free_vars = free_vars(body)
        self.free_vars.difference_update(args)
        self.depends = set()

        # For tarjan find SCC
        self.index = null
        self.lowlink = null
        self.on_stack = false

    +repr = (self):
        return repr(["Def", self.name, self.args, self.body])

# TODO: to really test this out 'proper', we also may want
#       freeform record types

free_vars = (a):
    if isinstance(a, Let)
        r = free_vars(a.rhs)
        r.discard(a.name)
        r.update( free_vars(a.lhs) )
        return r
    if isinstance(a, Abs)
        r = free_vars(a.body)
        for arg in a.args
            r.discard(arg)
        return r
    if isinstance(a, App)
        r = free_vars(a.lhs)
        for arg in a.args
            r.update(free_vars(arg))
        return r
    if isinstance(a, IfThenElse)
        r = free_vars(a.cond)
        r.update(free_vars(a.t))
        r.update(free_vars(a.f))
        return r
    if isinstance(a, Var)
        return set([a.name])
    if isinstance(a, Lit)
        return set()
    assert false, ["free vars for?", a]

class Let
    +init = (self, name, lhs, rhs):
        self.name = name
        self.lhs = lhs
        self.rhs = rhs

    +repr = (self):
        return repr(["Let", self.name, self.lhs, self.rhs])

class Abs
    +init = (self, args, body):
        self.args = args
        self.body = body

    +repr = (self):
        return repr(["Abs", self.args, self.body])

class App
    +init = (self, lhs, args):
        self.lhs = lhs
        self.args = args

    +repr = (self):
        return repr(["App", self.lhs, self.args])

class IfThenElse
    +init = (self, cond, t, f):
        self.cond = cond
        self.t = t
        self.f = f

    +repr = (self):
        return repr(["If", self.cond, self.t, self.f])

class Var
    +init = (self, name):
        self.name = name

    +repr = (self):
        return self.name

class Lit
    +init = (self, value, type):
        self.value = value
        self.type = type

    +repr = (self):
        return repr(["Lit", self.value, self.type])

actions = object({
    def = Def
    let = Let
    abs = Abs
    app = App
    if_then_else = IfThenElse
    var = Var
    string = (val):
        return Lit(val, "string")
    int = (val):
        return Lit(val, "int")
})
